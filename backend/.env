# Ollama Configuration
OLLAMA_API_URL=http://localhost:11434/api/generate  # Correct endpoint
OLLAMA_MODEL=mistral  # Changed from llama2
OLLAMA_TIMEOUT=30
OLLAMA_NUM_GPU=1  # If you have GPU acceleration